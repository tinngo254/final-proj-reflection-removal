{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os,time,cv2,scipy.io\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.slim as slim\n",
    "import tf_slim as slim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from discriminator import build_discriminator\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "WARNING:tensorflow:From <ipython-input-2-cba8a2e7faf2>:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "# ENVIRONMENT\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# TENSORFLOW 2.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print('GPU available:', tf.test.is_gpu_available())\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Add, BatchNormalization, Conv2D, Dense, Flatten, Input, LeakyReLU, PReLU, Lambda, MaxPool2D\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "\n",
    "from tensorflow.keras.metrics import Mean\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "# ESSENTIAL \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# VISUALIZER\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from IPython import display\n",
    "\n",
    "# UTILS\n",
    "import time\n",
    "from datetime import date\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "tf.random.set_seed(27)\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained VGG \n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19\n",
    "vgg_19 = VGG19(input_shape=(None, None, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "def _vgg(output_layer):\n",
    "    return Model(vgg_19.input, vgg_19.layers[output_layer].output)\n",
    "\n",
    "def vgg_52(input):\n",
    "    input = tf.cast(input * 255., dtype=tf.float32)\n",
    "    r, g, b = tf.split(input, 3, 3)\n",
    "    bgr = tf.concat([b - vgg_mean[0],\n",
    "                     g - vgg_mean[1],\n",
    "                     r - vgg_mean[2]], axis=3)\n",
    "    return _vgg(18)(bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_path=scipy.io.loadmat('./imagenet-vgg-verydeep-19.mat')\n",
    "vgg_layers=vgg_path['layers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_bias(vgg_layers,i):\n",
    "    weights=vgg_layers[i][0][0][2][0][0]\n",
    "    weights=tf.constant(weights)\n",
    "    \n",
    "    bias=vgg_layers[i][0][0][2][0][1]\n",
    "    bias=tf.constant(np.reshape(bias,(bias.size)))\n",
    "    return weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net(ntype,nin,nwb=None,name=None):\n",
    "    if ntype=='conv':\n",
    "        return tf.nn.relu(tf.nn.conv2d(nin,nwb[0],strides=[1,1,1,1],padding='SAME',name=name)+  nwb[1])\n",
    "    elif ntype=='pool':\n",
    "        return tf.nn.avg_pool(nin,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg19(input,reuse=False):\n",
    "    net={}\n",
    "    vgg_layers=vgg_path['layers'][0]\n",
    "    \n",
    "    net['input']= input - np.array([123.6800, 116.7790, 103.9390]).reshape((1,1,1,3))\n",
    "    \n",
    "    net['conv1_1']=build_net('conv',net['input'],get_weight_bias(vgg_layers,0),name='vgg_conv1_1')\n",
    "    net['conv1_2']=build_net('conv',net['conv1_1'],get_weight_bias(vgg_layers,2),name='vgg_conv1_2')\n",
    "    net['pool1']=build_net('pool',net['conv1_2'])\n",
    "    net['conv2_1']=build_net('conv',net['pool1'],get_weight_bias(vgg_layers,5),name='vgg_conv2_1')\n",
    "    net['conv2_2']=build_net('conv',net['conv2_1'],get_weight_bias(vgg_layers,7),name='vgg_conv2_2')\n",
    "    net['pool2']=build_net('pool',net['conv2_2'])\n",
    "    net['conv3_1']=build_net('conv',net['pool2'],get_weight_bias(vgg_layers,10),name='vgg_conv3_1')\n",
    "    net['conv3_2']=build_net('conv',net['conv3_1'],get_weight_bias(vgg_layers,12),name='vgg_conv3_2')\n",
    "    net['conv3_3']=build_net('conv',net['conv3_2'],get_weight_bias(vgg_layers,14),name='vgg_conv3_3')\n",
    "    net['conv3_4']=build_net('conv',net['conv3_3'],get_weight_bias(vgg_layers,16),name='vgg_conv3_4')\n",
    "    net['pool3']=build_net('pool',net['conv3_4'])\n",
    "    net['conv4_1']=build_net('conv',net['pool3'],get_weight_bias(vgg_layers,19),name='vgg_conv4_1')\n",
    "    net['conv4_2']=build_net('conv',net['conv4_1'],get_weight_bias(vgg_layers,21),name='vgg_conv4_2')\n",
    "    net['conv4_3']=build_net('conv',net['conv4_2'],get_weight_bias(vgg_layers,23),name='vgg_conv4_3')\n",
    "    net['conv4_4']=build_net('conv',net['conv4_3'],get_weight_bias(vgg_layers,25),name='vgg_conv4_4')\n",
    "    net['pool4']=build_net('pool',net['conv4_4'])\n",
    "    net['conv5_1']=build_net('conv',net['pool4'],get_weight_bias(vgg_layers,28),name='vgg_conv5_1')\n",
    "    net['conv5_2']=build_net('conv',net['conv5_1'],get_weight_bias(vgg_layers,30),name='vgg_conv5_2')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator (a.k.a Reflection Removal Model)\n",
    "# initializer = tf.keras.initializers.Identity(gain= 1.0)\n",
    "initializer = tf.initializers.he_normal(seed=None)\n",
    "\n",
    "\n",
    "def activation_normalizer(layer):\n",
    "    layer = tf.keras.layers.LeakyReLU(0.2)(layer)\n",
    "    layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "    return layer\n",
    "    \n",
    "    \n",
    "def build_gen(input_shape):\n",
    "    \n",
    "    x_input = tf.keras.layers.Input(shape = input_shape)\n",
    "    \n",
    "    vgg19_features = vgg_52(x_input) \n",
    "    \n",
    "    gen = tf.keras.layers.Conv2D(filters= 64, kernel_size= [1,1], dilation_rate= 1,padding= 'same', kernel_initializer= initializer)(vgg19_features)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 1, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 2, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 4, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 8, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 16, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 32, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 64, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    gen = tf.keras.layers.Conv2D(64, kernel_size= [3,3], dilation_rate= 1, padding= 'same', kernel_initializer= initializer)(gen)\n",
    "    gen = activation_normalizer(gen)\n",
    "    # last layer\n",
    "    gen = tf.keras.layers.Conv2D(6, kernel_size= [1,1], dilation_rate= 1, padding= 'same')(gen)\n",
    "    gen = Model(x_input, gen)\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_gen((None, None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, None, None,  0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split_1 (TensorFlow [(None, None, None,  0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_3 (TensorFlowOp [(None, None, None,  0           tf_op_layer_split_1[0][2]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_4 (TensorFlowOp [(None, None, None,  0           tf_op_layer_split_1[0][1]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_5 (TensorFlowOp [(None, None, None,  0           tf_op_layer_split_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, None, None,  0           tf_op_layer_sub_3[0][0]          \n",
      "                                                                 tf_op_layer_sub_4[0][0]          \n",
      "                                                                 tf_op_layer_sub_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, None, None, 5 15304768    tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 6 32832       model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 6 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 6 256         leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 6 36928       batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 6 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 6 256         leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 6 36928       batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 6 0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 6 256         leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 6 36928       batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 6 0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 6 256         leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 6 36928       batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 6 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 6 256         leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 6 36928       batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 6 0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 6 256         leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 6 36928       batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 6 0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 6 256         leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 6 36928       batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 6 0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 6 256         leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 6 36928       batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 6 0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 6 256         leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 6 390         batch_normalization_53[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 15,635,718\n",
      "Trainable params: 15,634,566\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

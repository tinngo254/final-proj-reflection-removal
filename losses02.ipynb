{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os,time,cv2,scipy.io\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.slim as slim\n",
    "import tf_slim as slim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from discriminator import build_discriminator\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "WARNING:tensorflow:From <ipython-input-2-cba8a2e7faf2>:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "# ENVIRONMENT\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# TENSORFLOW 2.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print('GPU available:', tf.test.is_gpu_available())\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Add, BatchNormalization, Conv2D, Dense, Flatten, Input, LeakyReLU, PReLU, Lambda, MaxPool2D\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError, MeanSquaredError\n",
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "\n",
    "from tensorflow.keras.metrics import Mean\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "# ESSENTIAL \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# VISUALIZER\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from IPython import display\n",
    "\n",
    "# UTILS\n",
    "import time\n",
    "from datetime import date\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 loss\n",
    "def compute_l1_loss(in_img, out_img):\n",
    "    return tf.reduce_mean(tf.abs(in_img - out_img))\n",
    "\n",
    "# L1 loss on reflection image\n",
    "## loss_l1_r = tf.where(issyn, compute_l1_loss(reflection_layer, reflection), 0)\n",
    "# loss_l1_r = compute_l1_loss(reflection_layer, reflection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perceptual loss (get layer of VGG)\n",
    "# def compute_percep_loss(input, output, reuse=False):\n",
    "#     vgg_real=build_vgg19(output*255.0, reuse=reuse)\n",
    "#     vgg_fake=build_vgg19(input*255.0, reuse=True)\n",
    "#     p0=compute_l1_loss(vgg_real['input'],vgg_fake['input'])\n",
    "#     p1=compute_l1_loss(vgg_real['conv1_2'],vgg_fake['conv1_2'])/2.6\n",
    "#     p2=compute_l1_loss(vgg_real['conv2_2'],vgg_fake['conv2_2'])/4.8\n",
    "#     p3=compute_l1_loss(vgg_real['conv3_2'],vgg_fake['conv3_2'])/3.7\n",
    "#     p4=compute_l1_loss(vgg_real['conv4_2'],vgg_fake['conv4_2'])/5.6\n",
    "#     p5=compute_l1_loss(vgg_real['conv5_2'],vgg_fake['conv5_2'])*10/1.5\n",
    "#     return p0+p1+p2+p3+p4+p5\n",
    "\n",
    "\n",
    "# # Perceptual Loss\n",
    "# loss_percep_t = compute_percep_loss(transmission_layer, target)\n",
    "# loss_percep_r = tf.where(issyn, compute_percep_loss(reflection_layer, reflection, reuse=True), 0.)\n",
    "# loss_percep = tf.where(issyn, loss_percep_t+loss_percep_r, loss_percep_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained VGG \n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19\n",
    "vgg_19 = VGG19(input_shape=(None, None, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptual loss (get layer of VGG)\n",
    "def _vgg(output_layer):\n",
    "    return Model(vgg_19.input, vgg_19.layers[output_layer].output)\n",
    "\n",
    "block_vgg_0 = _vgg(0)\n",
    "block_vgg_1 = _vgg(2)\n",
    "block_vgg_2 = _vgg(5)\n",
    "block_vgg_3 = _vgg(8)\n",
    "block_vgg_4 = _vgg(13)\n",
    "block_vgg_5 = _vgg(18)\n",
    "\n",
    "block_vgg_list = []\n",
    "for i in range(0, 7):\n",
    "    block_vgg_list.append( eval('block_vgg_{}'.format(i)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "=================================================================\n",
      "Total params: 260,160\n",
      "Trainable params: 260,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_vgg_list[2].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "def preprocess_vgg(in_img):\n",
    "    in_img = tf.cast(in_img * 255., dtype=tf.float32)\n",
    "    r, g, b = tf.split(in_img, 3, 3)\n",
    "    bgr = tf.concat([b - vgg_mean[0],\n",
    "                     g - vgg_mean[1],\n",
    "                     r - vgg_mean[2]], axis=3)\n",
    "    return bgr\n",
    "\n",
    "def vgg_loss_block(in_img, block_num):\n",
    "    img = preprocess_vgg(in_img)\n",
    "    return block_vgg_list[block_num](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_percep_loss(in_img, out_img, reuse=False):\n",
    "def compute_percep_loss(in_img, out_img):\n",
    "    p0 = compute_l1_loss(vgg_loss_block(out_img, 0), vgg_loss_block(out_img, 0))             # Input, layer 0\n",
    "    p1 = compute_l1_loss(vgg_loss_block(out_img, 2), vgg_loss_block(out_img, 2)) /2.6        # conv1_2, layer 2   \n",
    "    p2 = compute_l1_loss(vgg_loss_block(out_img, 5), vgg_loss_block(out_img, 5)) /4.8        # conv2_2, layer 5 \n",
    "    p3 = compute_l1_loss(vgg_loss_block(out_img, 8), vgg_loss_block(out_img, 8)) /3.7        # conv3_2, layer 8 \n",
    "    p4 = compute_l1_loss(vgg_loss_block(out_img, 13), vgg_loss_block(out_img, 13)) /5.6      # conv4_2, layer 13 \n",
    "    p5 = compute_l1_loss(vgg_loss_block(out_img, 18), vgg_loss_block(out_img, 18)) *10/1.5   # conv5_2, layer 18 \n",
    "\n",
    "    return p0+p1+p2+p3+p4+p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptual Loss\n",
    "loss_percep_t = compute_percep_loss(transmission_layer, target)\n",
    "# loss_percep_r = tf.where(issyn, compute_percep_loss(reflection_layer, reflection, reuse=True), 0.)\n",
    "loss_percep_r = compute_percep_loss(reflection_layer, reflection)\n",
    "# loss_percep = tf.where(issyn, loss_percep_t+loss_percep_r, loss_percep_t)\n",
    "loss_percep = loss_percep_t + loss_percep_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32, 32, 512), dtype=float32, numpy=\n",
       "array([[[[  0.       ,   0.       ,  87.70332  , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "            0.       ,  31.945353 ],\n",
       "         [  0.       ,  94.94548  ,  55.095768 , ...,   0.       ,\n",
       "            0.       , 181.53154  ],\n",
       "         ...,\n",
       "         [  0.       , 270.8574   ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [ 30.501225 , 194.59703  ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [ 12.462572 ,  53.652515 ,  47.653477 , ...,   0.       ,\n",
       "            0.       ,   0.       ]],\n",
       "\n",
       "        [[ 34.578876 , 255.89658  ,  71.654274 , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       , 173.34218  ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       , 123.29019  ,  49.671616 , ...,   0.       ,\n",
       "            0.       ,  71.68013  ],\n",
       "         ...,\n",
       "         [  0.       , 109.96734  ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [ 29.914762 , 289.1567   ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       , 222.3538   ,   0.       , ...,   0.       ,\n",
       "            0.       ,  66.38707  ]],\n",
       "\n",
       "        [[  0.       ,  61.53946  , 106.229385 , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       ,   0.       ,  67.83617  , ...,   0.       ,\n",
       "           36.756588 ,   0.       ],\n",
       "         [  0.       ,   0.       ,  65.95306  , ...,   0.       ,\n",
       "           21.158955 ,   0.       ],\n",
       "         ...,\n",
       "         [  0.       , 179.87572  ,   0.       , ...,  53.515358 ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       , 386.92557  ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       , 347.0355   ,   0.       , ...,   0.       ,\n",
       "            0.       ,  77.27961  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.       ,  74.32588  , 134.67525  , ...,   0.       ,\n",
       "            0.       , 229.53091  ],\n",
       "         [  0.       , 178.52217  ,  91.97136  , ...,   0.       ,\n",
       "            0.       , 250.38449  ],\n",
       "         [  0.       , 241.16159  ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         ...,\n",
       "         [  0.       ,   0.       ,  94.010735 , ...,   0.       ,\n",
       "            0.       , 106.638855 ],\n",
       "         [  0.       ,  83.9162   ,  39.021656 , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       ,  67.085396 ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ]],\n",
       "\n",
       "        [[ 36.39996  ,   7.0637674, 158.15555  , ...,   0.       ,\n",
       "            0.       , 164.03734  ],\n",
       "         [ 64.87705  ,  26.893167 ,  83.488815 , ...,   0.       ,\n",
       "            0.       , 136.70792  ],\n",
       "         [ 51.150204 , 114.63974  ,  31.263105 , ...,  38.64769  ,\n",
       "            0.       ,   0.       ],\n",
       "         ...,\n",
       "         [  0.       ,  72.645096 ,  98.10834  , ...,   0.       ,\n",
       "            0.       , 107.81308  ],\n",
       "         [  0.       , 232.49776  , 114.02788  , ...,   0.       ,\n",
       "            0.       ,   0.       ],\n",
       "         [  0.       , 202.64346  ,   0.       , ...,   0.       ,\n",
       "            0.       ,   0.       ]],\n",
       "\n",
       "        [[ 20.464035 ,  76.219574 , 181.85187  , ...,   0.       ,\n",
       "            0.       , 114.75437  ],\n",
       "         [ 61.18232  ,  12.818199 , 121.291534 , ...,   0.       ,\n",
       "            0.       ,  99.78986  ],\n",
       "         [ 51.420223 ,  28.492643 , 113.61197  , ...,   0.       ,\n",
       "            0.       ,   9.294221 ],\n",
       "         ...,\n",
       "         [  0.       ,  25.678675 , 161.04723  , ...,   0.       ,\n",
       "            0.       , 148.31941  ],\n",
       "         [  0.       , 120.0194   , 185.08089  , ...,   0.       ,\n",
       "            0.       , 113.43535  ],\n",
       "         [  0.       , 161.4169   ,  11.821674 , ...,  11.657436 ,\n",
       "            0.       ,  65.76502  ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vgg_18 = vgg_52(output_t)\n",
    "\n",
    "# vgg_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12\n",
    "\n",
    "# Adversarial Loss\n",
    "predict_real = build_discriminator(input_img, target)\n",
    "    \n",
    "predict_fake = build_discriminator(input_img, transmission_layer)\n",
    "    \n",
    "# Compute GAN loss\n",
    "d_loss = (tf.reduce_mean(-(tf.log(predict_real + EPS) + tf.log(1 - predict_fake + EPS)))) * 0.5\n",
    "g_loss = tf.reduce_mean(-tf.log(predict_fake + EPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusion loss, in gradient domain\n",
    "def compute_gradient(img):\n",
    "    gradx = img[:,1:,:,:] - img[:,:-1,:,:]\n",
    "    grady = img[:,:,1:,:] - img[:,:,:-1,:]\n",
    "    return gradx, grady\n",
    "\n",
    "def compute_exclusion_loss(img1, img2, level=1):\n",
    "    gradx_loss=[]\n",
    "    grady_loss=[]\n",
    "    \n",
    "    for l in range(level):\n",
    "        gradx1, grady1 = compute_gradient(img1)\n",
    "        gradx2, grady2 = compute_gradient(img2)\n",
    "        alphax = 2.0* tf.reduce_mean(tf.abs(gradx1)) / tf.reduce_mean(tf.abs(gradx2))\n",
    "        alphay = 2.0* tf.reduce_mean(tf.abs(grady1)) / tf.reduce_mean(tf.abs(grady2))\n",
    "        \n",
    "        gradx1_s = (tf.keras.activations.sigmoid(gradx1) *2) -1\n",
    "        grady1_s = (tf.keras.activations.sigmoid(grady1) *2) -1\n",
    "        gradx2_s=(tf.keras.activations.sigmoid(gradx2 *alphax) *2) -1\n",
    "        grady2_s=(tf.keras.activations.sigmoid(grady2 *alphay) *2) -1\n",
    "\n",
    "        gradx_loss.append( tf.reduce_mean( tf.multiply( tf.square(gradx1_s), tf.square(gradx2_s)) ) **0.25)\n",
    "        grady_loss.append( tf.reduce_mean( tf.multiply( tf.square(grady1_s), tf.square(grady2_s)) ) **0.25)\n",
    "\n",
    "#         img1= tf.nn.avg_pool(img1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "#         img2= tf.nn.avg_pool(img2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "        img1= tf.keras.layers.AveragePooling2D( pool_size= (2,2), padding='SAME')(img1)\n",
    "        img2= tf.keras.layers.AveragePooling2D( pool_size= (2,2), padding='SAME')(img2)\n",
    "        \n",
    "    return gradx_loss, grady_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient loss\n",
    "# loss_gradx, loss_grady = compute_exclusion_loss(transmission_layer, reflection_layer, level=3)\n",
    "# loss_gradxy = tf.reduce_sum(sum(loss_gradx) /3.) + tf.reduce_sum(sum(loss_grady) /3.)\n",
    "## loss_grad = tf.where(issyn, loss_gradxy/2.0, 0)\n",
    "# loss_grad = loss_gradxy / 2.0\n",
    "\n",
    "\n",
    "# loss = loss_l1_r + loss_percep *0.2 + loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_test = cv2.imread('./Test-Images/back_2.jpg', -1)\n",
    "blend_test = cv2.imread('./Test-Images/blended_2.jpg', -1)\n",
    "\n",
    "##########\n",
    "neww = 512\n",
    "newh = 512\n",
    "\n",
    "channel = 64\n",
    "##########\n",
    "output_t=cv2.resize(np.float32(trans_test),(neww,newh),cv2.INTER_CUBIC)/255.0\n",
    "output_b=cv2.resize(np.float32(blend_test),(neww,newh),cv2.INTER_CUBIC)/255.0\n",
    "\n",
    "#########\n",
    "output_t = np.expand_dims(output_t,axis=0)\n",
    "output_b = np.expand_dims(output_b,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient loss\n",
    "loss_gradx, loss_grady = compute_exclusion_loss(output_t, output_b, level=3)\n",
    "loss_gradxy = tf.reduce_sum(sum(loss_gradx) /3.) + tf.reduce_sum(sum(loss_grady) /3.)\n",
    "\n",
    "# issyn=tf.compat.v1.placeholder(tf.bool,shape=[])\n",
    "# loss_grad = tf.where(issyn, loss_gradxy/2.0, 0)\n",
    "loss_grad = loss_gradxy/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.17865163>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.089325815>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gradx, loss_grady\n",
    "loss_gradxy, loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
